# Automatic Harmful Listing Removal - Complete Package

## ğŸ¯ What Was Built

An AI-powered content moderation system that automatically detects and removes harmful listings from your Campus Marketplace.

## ğŸ“‹ Quick Summary

**What it does:**
- âœ… Blocks harmful listings when users try to create them
- âœ… Scans existing listings for prohibited content
- âœ… Automatically removes unsafe listings
- âœ… Notifies users when their listings are removed
- âœ… Uses AI to detect drugs, alcohol, weapons, and other prohibited items

**How it works:**
- Real-time validation during listing creation
- Background jobs for periodic scanning
- Multi-layer detection (keywords + OpenAI AI)
- Email notifications for transparency

## ğŸ“ Files Created

### Services
- `app/services/content_safety_service.rb` - Main safety checking logic

### Jobs
- `app/jobs/content_safety_job.rb` - Background scanning job

### Views
- `app/views/report_mailer/listing_removed_for_safety.html.erb` - Email template

### Tasks
- `lib/tasks/safety.rake` - Command-line tools

### Documentation
- `CONTENT_SAFETY_SETUP.md` - Full setup guide
- `SAFETY_QUICK_START.md` - Quick start guide  
- `SAFETY_IMPLEMENTATION.md` - Technical details
- `TESTING_SAFETY.md` - Testing guide

## ğŸ“ Files Modified

- `app/models/listing.rb` - Added safety validation
- `app/mailers/report_mailer.rb` - Added removal notification
- `config/application.rb` - Added configuration

## ğŸš€ How to Use

### Step 1: Enable (already enabled by default)
```powershell
$env:CONTENT_SAFETY_ENABLED = "true"
$env:OPENAI_API_KEY = "your-key-here"
```

### Step 2: Restart server
```powershell
# Stop current server (Ctrl+C)
# Then start again
rails server
```

### Step 3: Test it
```powershell
# Try creating a listing with "beer" in the title - should be blocked
# Or check an existing listing
rails safety:check_listing[1]
```

### Step 4: Scan existing listings
```powershell
rails safety:scan
```

## ğŸ›¡ï¸ What Gets Blocked

- **Drugs**: marijuana, pills, cocaine, etc.
- **Alcohol**: beer, wine, vodka, etc.
- **Weapons**: guns, knives, ammunition
- **Other**: fake IDs, stolen goods, counterfeit items

## ğŸ’° Cost

- Keyword checking: **FREE**
- OpenAI Moderation API: **FREE**
- Image analysis: **~$0.00015 per image** (optional)

## ğŸ“Š Features

### For Users
- Clear error messages when posting prohibited content
- Email notifications if listing is removed
- Appeal process for mistakes

### For Admins
- Automated scanning
- Manual check tools
- Configurable sensitivity
- Detailed logging

## ğŸ”§ Commands

```powershell
# Scan all listings and remove unsafe ones
rails safety:scan

# Check if a specific listing is safe (without removing)
rails safety:check_listing[123]

# Check configuration
rails runner "puts Rails.application.config.content_safety_enabled"
```

## ğŸ“š Documentation

1. **`SAFETY_QUICK_START.md`** â† Start here!
2. **`CONTENT_SAFETY_SETUP.md`** - Detailed setup
3. **`TESTING_SAFETY.md`** - How to test
4. **`SAFETY_IMPLEMENTATION.md`** - Technical details

## ğŸ“ Example Usage

### Example 1: User tries to post alcohol
```
User: Creates listing "Beer for sale - $10"
System: âŒ BLOCKED
Message: "This listing cannot be published: Contains prohibited 
         keyword: beer. Please ensure your listing does not contain 
         prohibited items (drugs, alcohol, weapons, etc.)"
```

### Example 2: Existing listing is flagged
```
Admin: Runs 'rails safety:scan'
System: Finds listing "Vodka bottle"
System: Deletes listing
System: Sends email to user explaining removal
User: Gets email with reason and appeal instructions
```

### Example 3: Safe listing passes
```
User: Creates listing "Calculus Textbook - $40"
System: âœ… PASSED - Keyword check
System: âœ… PASSED - AI moderation
System: Listing published successfully
```

## âš™ï¸ Configuration Options

| Setting | Default | Purpose |
|---------|---------|---------|
| `CONTENT_SAFETY_ENABLED` | `true` | Enable/disable feature |
| `OPENAI_API_KEY` | (required) | API key for AI checks |

## ğŸ” Monitoring

View safety-related logs:
```powershell
Get-Content log\development.log -Tail 100 | Select-String "ContentSafety"
```

## ğŸš¨ Troubleshooting

**Problem: Listings aren't being blocked**
- Check: `$env:CONTENT_SAFETY_ENABLED` should be "true"
- Check: Server was restarted after setting env vars

**Problem: All listings are being blocked**
- The keyword list might be too strict
- Check logs for specific reasons
- Adjust keywords in `content_safety_service.rb`

**Problem: API errors**
- Check: `$env:OPENAI_API_KEY` is set correctly
- Check: You have internet connection
- Note: Keyword checking still works without API

## ğŸ“ˆ Best Practices

1. **Run initial scan** after setup to clean existing listings
2. **Schedule regular scans** (daily or weekly)
3. **Monitor logs** for patterns
4. **Adjust keywords** for your campus policies
5. **Communicate policies** clearly to users

## ğŸ‰ Success Criteria

You'll know it's working when:
- âœ… Creating a listing with "beer" gets blocked
- âœ… Running `rails safety:scan` completes without errors
- âœ… Logs show safety checks happening
- âœ… Test listing gets correctly flagged/approved

## ğŸ“ Support

- **Quick questions**: See `SAFETY_QUICK_START.md`
- **Setup help**: See `CONTENT_SAFETY_SETUP.md`
- **Testing**: See `TESTING_SAFETY.md`
- **Technical details**: See `SAFETY_IMPLEMENTATION.md`

## ğŸ” Security & Privacy

- âœ… No data stored by OpenAI
- âœ… All checks server-side
- âœ… User privacy protected
- âœ… Appeal process available
- âœ… Transparent notifications

## ğŸ¯ What's Next?

After you've set this up:

1. **Test it thoroughly** - Use `TESTING_SAFETY.md` guide
2. **Run initial scan** - Clean up existing listings
3. **Set up scheduled scans** - For ongoing monitoring
4. **Educate users** - Add policies to your site
5. **Monitor and adjust** - Fine-tune based on results

---

## ğŸŒŸ Summary

You now have a production-ready content safety system that:
- Prevents harmful listings from being created
- Automatically removes existing unsafe content
- Notifies users professionally
- Costs almost nothing to run
- Works with your existing OpenAI setup

**Ready to deploy!** ğŸš€

For detailed instructions, start with: **`SAFETY_QUICK_START.md`**
